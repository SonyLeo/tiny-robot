import{I as i}from"./index.DK1_8fsF.js";import{L as p}from"./index.DxNZ-LWs.js";import{O as c}from"./index.CrilgvuA.js";import{d as u,p as a,c as d,o as s,b as f,e as v,G as g,k as m,F as k}from"./framework.DrGfhPAt.js";import"./loading.CaA-rOal.js";import"./utils.nxwM3ABj.js";import"./index2.BzGNBP-0.js";import"./tiny-robot-svgs.BbDZZ-ON.js";import"./plugin-vue_export-helper.lGy7RumW.js";import"./index.DEUmgi2i.js";import"./index.DHtMHeZQ.js";import"./index.DEgDKdua.js";import"./index.Bvo3FQtB.js";import"./loading-shadow.BiLqD-EG.js";import"./help-circle.DC-W0qVG.js";const M=u({__name:"Basic",setup(V){const t=a(""),r=a("hello");async function l(n){const e=new c({provider:"openai",defaultModel:"gpt-3.5-turbo",apiUrl:location.origin+"/tiny-robot/alpha/"});try{const o=await e.chat({messages:[{role:"user",content:n}],options:{temperature:.7}});t.value=o.choices[0].message.content}catch(o){console.error("聊天出错:",o)}}return(n,e)=>(s(),d(k,null,[t.value?(s(),f(m(i),{key:0,content:t.value},null,8,["content"])):v("",!0),g(m(p),{modelValue:r.value,"onUpdate:modelValue":e[0]||(e[0]=o=>r.value=o),onSubmit:e[1]||(e[1]=o=>l(r.value))},null,8,["modelValue"])],64))}});export{M as default};
