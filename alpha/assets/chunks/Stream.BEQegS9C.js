import{M as f,w as g}from"./theme.C_-hLVRq.js";import{O as v}from"./index.NsULz9jf.js";import{d as b,p as c,c as k,o as u,b as V,e as w,G as y,k as i,F as C}from"./framework.CdlzW3Za.js";const S=b({__name:"Stream",setup(_){const n=c(""),a=c("hello");let o;async function m(r){const t=new v({provider:"openai",defaultModel:"gpt-3.5-turbo",apiUrl:location.origin+"/tiny-robot/alpha/"});try{o=new AbortController,await t.chatStream({messages:[{role:"user",content:r}],options:{signal:o.signal,temperature:.7}},{onData:e=>{var l,s;const d=((s=(l=e.choices[0])==null?void 0:l.delta)==null?void 0:s.content)||"";n.value+=d},onError:e=>{console.error("流式响应错误:",e),o=null},onDone:()=>{console.log(`
流式响应完成`),o=null}})}catch(e){console.error("聊天出错:",e)}}function p(){o&&(o.abort(),o=null)}return(r,t)=>(u(),k(C,null,[n.value?(u(),V(i(f),{key:0,content:n.value},null,8,["content"])):w("",!0),y(i(g),{modelValue:a.value,"onUpdate:modelValue":t[0]||(t[0]=e=>a.value=e),onSubmit:t[1]||(t[1]=e=>m(a.value)),onCancel:p},null,8,["modelValue"])],64))}});export{S as default};
