import{I as f}from"./index.DK1_8fsF.js";import{L as g}from"./index.DxNZ-LWs.js";import{O as v}from"./index.CrilgvuA.js";import{d as b,p as m,c as k,o as s,b as V,e as y,G as C,k as c,F as _}from"./framework.DrGfhPAt.js";import"./loading.CaA-rOal.js";import"./utils.nxwM3ABj.js";import"./index2.BzGNBP-0.js";import"./tiny-robot-svgs.BbDZZ-ON.js";import"./plugin-vue_export-helper.lGy7RumW.js";import"./index.DEUmgi2i.js";import"./index.DHtMHeZQ.js";import"./index.DEgDKdua.js";import"./index.Bvo3FQtB.js";import"./loading-shadow.BiLqD-EG.js";import"./help-circle.DC-W0qVG.js";const O=b({__name:"Stream",setup(h){const n=m(""),r=m("hello");let e;async function p(a){const t=new v({provider:"openai",defaultModel:"gpt-3.5-turbo",apiUrl:location.origin+"/tiny-robot/alpha/"});try{e=new AbortController,await t.chatStream({messages:[{role:"user",content:a}],options:{signal:e.signal,temperature:.7}},{onData:o=>{var l,i;const d=((i=(l=o.choices[0])==null?void 0:l.delta)==null?void 0:i.content)||"";n.value+=d},onError:o=>{console.error("流式响应错误:",o),e=null},onDone:()=>{console.log(`
流式响应完成`),e=null}})}catch(o){console.error("聊天出错:",o)}}function u(){e&&(e.abort(),e=null)}return(a,t)=>(s(),k(_,null,[n.value?(s(),V(c(f),{key:0,content:n.value},null,8,["content"])):y("",!0),C(c(g),{modelValue:r.value,"onUpdate:modelValue":t[0]||(t[0]=o=>r.value=o),onSubmit:t[1]||(t[1]=o=>p(r.value)),onCancel:u},null,8,["modelValue"])],64))}});export{O as default};
