import{L as f,x as g}from"./theme.FCGLGkiy.js";import{x as v}from"./index.Y854Y0Ii.js";import{d as b,p as c,c as k,o as u,b as V,e as x,G as y,k as i,F as C}from"./framework.CSeOnaMy.js";const L=b({__name:"Stream",setup(_){const n=c(""),a=c("hello");let o;async function m(r){const t=new v({provider:"openai",defaultModel:"gpt-3.5-turbo",apiUrl:location.origin+"/tiny-robot/alpha/"});try{o=new AbortController,await t.chatStream({messages:[{role:"user",content:r}],options:{signal:o.signal,temperature:.7}},{onData:e=>{var l,s;const d=((s=(l=e.choices[0])==null?void 0:l.delta)==null?void 0:s.content)||"";n.value+=d},onError:e=>{console.error("流式响应错误:",e),o=null},onDone:()=>{console.log(`
流式响应完成`),o=null}})}catch(e){console.error("聊天出错:",e)}}function p(){o&&(o.abort(),o=null)}return(r,t)=>(u(),k(C,null,[n.value?(u(),V(i(f),{key:0,content:n.value},null,8,["content"])):x("",!0),y(i(g),{modelValue:a.value,"onUpdate:modelValue":t[0]||(t[0]=e=>a.value=e),onSubmit:t[1]||(t[1]=e=>m(a.value)),onCancel:p},null,8,["modelValue"])],64))}});export{L as default};
