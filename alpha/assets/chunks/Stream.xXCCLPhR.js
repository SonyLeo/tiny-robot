import{d as f,n as g}from"./theme.4Bph1Nvo.js";import{O as v}from"./index.ziJS6HM3.js";import{d as b,p as c,c as k,o as u,b as V,e as y,G as C,k as i,F as _}from"./framework.BnsMRgQR.js";const x=b({__name:"Stream",setup(h){const t=c(""),a=c("hello");let o;async function m(r){const n=new v({provider:"openai",defaultModel:"gpt-3.5-turbo",apiUrl:location.origin+"/tiny-robot/alpha/"});try{o=new AbortController,await n.chatStream({messages:[{role:"user",content:r}],options:{signal:o.signal,temperature:.7}},{onData:e=>{var l,s;const d=((s=(l=e.choices[0])==null?void 0:l.delta)==null?void 0:s.content)||"";t.value+=d},onError:e=>{console.error("流式响应错误:",e),o=null},onDone:()=>{console.log(`
流式响应完成`),o=null}})}catch(e){console.error("聊天出错:",e)}}function p(){o&&(o.abort(),o=null)}return(r,n)=>(u(),k(_,null,[t.value?(u(),V(i(f),{key:0,content:t.value},null,8,["content"])):y("",!0),C(i(g),{modelValue:a.value,"onUpdate:modelValue":n[0]||(n[0]=e=>a.value=e),onSubmit:n[1]||(n[1]=e=>m(a.value)),onCancel:p},null,8,["modelValue"])],64))}});export{x as default};
